{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "614baf4b-b7d2-4269-b2f5-dc655cdec49b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ejercicios evaluables - Matemáticas para la IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886cb707-50b1-47d2-b356-2bbf78a9cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d549f8-88ef-4554-a239-b5811383bac7",
   "metadata": {},
   "source": [
    "### Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beff7b7-f4bc-4502-bda7-7f21127b7e0a",
   "metadata": {},
   "source": [
    "#### Apartado a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8fbe46-3950-4948-bde4-f31217ef8367",
   "metadata": {},
   "source": [
    "Se define en primer lugar la función *grad_func*, que tiene dos parámetros: el punto donde se evalua el gradiente y la función cuyo gradiente hay que calcular (o derivada en el caso unidimensional). Aquí es donde se crean los gradientes de las funciones f y g del enunciado.\n",
    "\n",
    "$f(x) = 3x^4 + 4x^3 − 12x^2 + 7  \\hspace{0.5cm} \\Longrightarrow \\hspace{0.5cm} f'(x) = 12x^3+12x^2-24x$\n",
    "\n",
    "$g(x, y) = x^2 + y^3 + 3xy + 1 \\hspace{0.5cm} \\Longrightarrow \\hspace{0.5cm} \\nabla g(x,y) = \\left( 2x+3y, 3x+3y^2 \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09356b01-36f5-4e12-8f5a-87bd9388b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_func(x, funcion):\n",
    "    \n",
    "    if funcion == 'f':\n",
    "        y = 12*(x**3)+12*(x**2)-24*x\n",
    "    else:\n",
    "        y = np.array([2*x[0]+3*x[1], 3*(x[1]**2)+3*x[0]])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86595d44-0a49-4d58-b33a-bca02c963ac8",
   "metadata": {},
   "source": [
    "Diseñamos ahora la funcion que implementa el método de descenso de gradiente con los parámetros descritos más el parámetro función comentado previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "093f8b67-9355-48de-95eb-e1bcacee3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descenso_grad(x, ratio, tol, maxit, funcion):\n",
    "    \n",
    "    grad_norm = linalg.norm(grad_func(x, funcion))\n",
    "    cont = 0 #contador de iteraciones\n",
    "    \n",
    "    while grad_norm >= tol and cont <= maxit:\n",
    "        grad = grad_func(x, funcion)\n",
    "        x = x - ratio*grad \n",
    "        grad_norm = linalg.norm(grad)\n",
    "        cont += 1\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e117ab3-f89c-4aac-b97e-669d4660f375",
   "metadata": {},
   "source": [
    "#### Apartado b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1cf424-d77a-45ed-91ed-c5c5fcdb23fb",
   "metadata": {},
   "source": [
    "1) Se aplica el método sobre $f(x)$ con los parámetros indicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40ebe5c0-1d33-4116-bd22-ec53935f2d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000266"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descenso_grad(3, 0.001, 1e-12, 1e5, 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53c53b-c965-4156-af80-cd0dec2c4819",
   "metadata": {},
   "source": [
    "2) Se aplica el método sobre $f(x)$ con los parámetros indicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b4a53e6-5b44-47ff-9133-077d8c276111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9999999999999967"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descenso_grad(3, 0.01, 1e-12, 1e5, 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f6552-a332-4bff-975e-ee975f157ebd",
   "metadata": {},
   "source": [
    "3) Como $f'(x) = 12x(x^2+x-2)$, se deduce fácilmente que los ceros de la derivada son x=0, 1, -2. Evaluando dichos puntos en la segunda derivada \n",
    "\n",
    "$$f''(x) = 36x^2 +24x-24,$$ \n",
    "\n",
    "se obtiene que:\n",
    "- $f''(0) = -24 < 0 \\quad \\Longrightarrow  0$ es un máximo.\n",
    "- $f''(1) = 36 > 0 \\quad  \\Longrightarrow  0$  es un mínimo.\n",
    "- $f''(-2) = 72 > 0 \\quad \\Longrightarrow  0$ es un mínimo.\n",
    "\n",
    "Aunque el punto inicial era el mismo para los apartados 1 y 2, el ratio era distinto. El ratio marca cuanto nos movemos en la dirección de mmáximo descenso. Por tanto, la elección de un ratio relativamente grande puede llegar a tener como consecuencia que converjamos a un mínimo que no es el más cercano al punto de partida. Incluso si el ratio es demasiado grande, el método puede llegar a no converger como se verá en el siguiente apartado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0212b7-0191-4818-9bc3-928461397b0f",
   "metadata": {},
   "source": [
    "4) Aplicamos el método sobre $f(x)$ con los parámetros indicados, pero al ejecutar nos da un error de que el valor es demasiado grande de calcular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9cc781d-563b-4cf4-b130-879a1288c40c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Result too large')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdescenso_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mdescenso_grad\u001b[1;34m(x, ratio, tol, maxit, funcion)\u001b[0m\n\u001b[0;32m      4\u001b[0m cont \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m grad_norm \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m tol \u001b[38;5;129;01mand\u001b[39;00m cont \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m maxit:\n\u001b[1;32m----> 7\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuncion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m ratio\u001b[38;5;241m*\u001b[39mgrad\n\u001b[0;32m      9\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39mnorm(grad)\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mgrad_func\u001b[1;34m(x, funcion)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_func\u001b[39m(x, funcion):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m funcion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 4\u001b[0m         y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m12\u001b[39m\u001b[38;5;241m*\u001b[39m(x\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m24\u001b[39m\u001b[38;5;241m*\u001b[39mx\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m         y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mx[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39m(x[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mx[\u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[1;31mOverflowError\u001b[0m: (34, 'Result too large')"
     ]
    }
   ],
   "source": [
    "descenso_grad(3, 0.1, 1e-12, 1e5, 'f') # Si se ejecuta da error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d330ca5e-36fb-41a0-a34e-c9693048eb4d",
   "metadata": {},
   "source": [
    "El motivo de que de error es que se está tomando un ratio demasiado grande. En la primera iteración $x_1$ vale: \n",
    "\n",
    "$$x_1 = x_0 - \\gamma  f'(x_0) = 3 - 0.1 360 = -33$$ En la segunda, \n",
    "\n",
    "$$x_2 = x_1 - \\gamma  f'(x_1) = -33 - 0.1 (-417384) = 41705.4$$ \n",
    "\n",
    "Y en la tercera:\n",
    "\n",
    "$$x_3 = x_2 - \\gamma  f'(x_2) = -87049951065956.78 $$\n",
    "\n",
    "Lo que esta ocurriendo es que en cada iteración se desplace en el sentido del mínimo, se esta desplazando 'de más' y por tanto el método no converge. Es decir, los puntos $x_n$ calculados van apareciendo a la izquierda y derecha del mínimo alternadamente  pero cada vez más lejos del mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c14f0-39dc-432c-8071-7f64053defce",
   "metadata": {},
   "source": [
    "5. Si aplicamos ahora el método con punto inicial 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3290d639-e916-4611-afe0-bd5221f9a648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descenso_grad(0, 0.001, 1e-12, 1e5, 'f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ab0ea-75f7-496a-8b42-cf84e3f48d12",
   "metadata": {},
   "source": [
    "Esto no es un resultado deseable puesto que es un máximo. Al ser un máximo la derivada se anula y nuestro método no funciona pues:\n",
    "$$x_1 = x_0 - \\gamma  f'(x_0) = 0 - 0 = 0,$$\n",
    "y en consecuencia todos los $x_$ sucesivos serán también cero, luego el método converge al mismo punto de inicio si es un máximo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde02618-e9be-45c1-a312-f4c57019dbc1",
   "metadata": {},
   "source": [
    "#### Apartado c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205cd94-2059-463a-9d02-8a92810fd69b",
   "metadata": {},
   "source": [
    "1) Se aplica el método con los parámetros indicados, se obtiene el punto donde se alcanza el mínimo, como se verá en el último apartado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52cbcd84-5360-48cc-b3c2-965b8dac10a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.25,  1.5 ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descenso_grad(np.array([-1,1]), 0.01, 1e-12, 1e5, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e611164-dcc7-45c3-aaa0-62d87ef47509",
   "metadata": {},
   "source": [
    "2. Si se parte ahora del punto origen, se obtiene un resultado no deseable pues (0,0) no es un mínimo como se verá en el siguiente apartado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "517dabd6-6bc4-42a1-a8a7-9137ea4fc37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descenso_grad(np.array([0,0]), 0.01, 1e-12, 1e5, 'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0cdaa-21f4-4523-8479-9ab4e6f2f26a",
   "metadata": {},
   "source": [
    "3. En el primer apartado a) obtuvimos el gradiente de $g(x,y)$. Igualando el gradiente al vector nulo se obtienen los puntos críticos (resolviendo un sistema de dos ecuaciones con dos incógnitas), que son: $a=(0,0)$ y $b=(-2.25, 1.5)$. Si calculamos la matriz Hessiana de $g$: \n",
    "\n",
    "$$ \\mathcal{H}_{(x,y)}g = \\begin{bmatrix}\n",
    "2 & 3 \\\\\n",
    "3 & 6y \n",
    "\\end{bmatrix}.  $$\n",
    "\n",
    "Esto implica que:\n",
    "$$ \\mathcal{H}_{a}g = \\begin{bmatrix}\n",
    "2 & 3 \\\\\n",
    "3 & 0 \n",
    "\\end{bmatrix} \\quad \\Longrightarrow  \\quad |\\mathcal{H}_{a}g| = -9 \\quad \\Longrightarrow \\quad a=(0,0) \\quad \\textrm{es un punto de silla}.$$\n",
    "y\n",
    "$$ \\mathcal{H}_{b}g = \\begin{bmatrix}\n",
    "2 & 3 \\\\\n",
    "3 & 9 \n",
    "\\end{bmatrix} \\quad \\Longrightarrow \\quad |\\mathcal{H}_{b}g| = 9 \\quad \\Longrightarrow \\quad b=(-2.25,1.5) \\quad \\textrm{es un mínimo (observe que el elemento 1,1 de la matriz también es positivo)}.$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
